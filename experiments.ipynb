{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e253c7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from langchain_classic.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fca9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY']=os.getenv('GROQ_API_KEY')\n",
    "os.environ['HF_TOKEN']=os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc684f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model='llama-3.1-8b-instant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47602e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_name=input('name')\n",
    "Email_Address=input('email address')\n",
    "phone_no=input('phone no')\n",
    "years_of_exp=input('experience')\n",
    "desired_positions=input('Desired position(s)')\n",
    "current_loc=input('current location')\n",
    "tech_stack=input('specify your tech stack, including programming languages, frameworks, databases, and tools you are proficient in.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aeccfe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "info='My name is {full_name}, I have {years_of_exp} years of experience, the position(s) I want to apply for is {desired_positions} and my tech stack includes {tech_stack}'\n",
    "info = Document(\n",
    "    page_content=info,\n",
    "    metadata={'type': 'Information', 'source': 'candidate_input'}\n",
    ")\n",
    "doc=[info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec1438c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chetan\\OneDrive\\Desktop\\recruitment_bot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings(model='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab46a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=FAISS.from_documents(doc,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fd99dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','You are an assistant who is specialised in interviewing and hiring candidates, you will ask every candidate 3-5 questions based on the provided tech stack, the questions should be of medium to hard type with some complexities.'),\n",
    "        ('human','{input}')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8728e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0db6260",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53088b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Chetan. Based on your tech stack, I\\'ll ask you some questions to assess your skills and experience. Here are 5 questions for you:\\n\\n1. **Python question**: You\\'re working with a large dataset of user interactions in a web application. The dataset is stored in a Pandas DataFrame, and you need to perform a complex aggregation operation involving multiple join operations and grouping by a categorical column. How would you approach this problem, and what methods would you use in Python to optimize the performance of the aggregation operation?\\n\\n2. **Groq question**: Groq is a query language specifically designed for working with large datasets. Suppose you have a Groq query that looks like this: `SELECT * FROM table WHERE column1 = \"value1\" AND column2 = \"value2\"` . However, the `column1` and `column2` columns are not indexed, and the dataset is very large. How would you optimize this query to improve its performance, and what Groq features would you use to achieve this?\\n\\n3. **LangChain question**: LangChain is a framework for building conversational AI applications. You\\'re building a chatbot that uses a combination of natural language processing (NLP) and machine learning (ML) to generate responses to user queries. Suppose the user asks a question that requires a specific piece of information from a database. How would you design the architecture of your chatbot to retrieve this information and incorporate it into the response, and what LangChain APIs would you use to achieve this?\\n\\n4. **Streamlit question**: You\\'re building a data exploration application using Streamlit, and you need to display a large dataset with many columns. However, some of the columns contain sensitive data that should not be visible to the users. How would you approach this problem, and what Streamlit features would you use to ensure that the sensitive data is hidden while still allowing users to interact with the dataset?\\n\\n5. **Optional question**: As a bonus question, I\\'ll give you a scenario that involves Power BI and SQL. Suppose you have a Power BI report that uses a SQL database as its data source. The report displays a dashboard with several visualizations, and the user wants to be able to export the data behind each visualization as a CSV file. How would you achieve this, and what Power BI features would you use to enable data export?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'name':full_name,'input':tech_stack})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3647590",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "get_history=RunnableWithMessageHistory(llm,get_session_history=get_session_history,input_messages_key='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47381ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'You are an assistant who is specialised in interviewing and hiring candidates, you will ask every candidate 3-5 questions based on the provided tech stack, the questions should be of medium to hard type with some complexities. Do NOT answer the question, just reformulate it if needed and otherwise return it as it is.'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'),\n",
    "        ('human','{input}')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60f6ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_retriever=create_history_aware_retriever(llm,retriever,history_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8792b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','You are a good assistant, give answers to the questions with respect to the context provided. keep the answers brief and should not exceed more than 3 points  \\n\\n context:{context}'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'),\n",
    "        ('human','{input}')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ee5768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain=create_retrieval_chain(history_retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1347ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_history=RunnableWithMessageHistory(rag_chain,get_session_history,input_messages_key='input',history_messages_key='chat_history',output_messages_key='answer',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0663379",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_history.invoke({'input':''})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
